# TAREA 3 - Procesamiento, Entrenamiento e Inferencia
## Alumno: Ulises Reyes GarcÃ­a
## CU: 152113

Este repositorio contiene un flujo completo para procesar datos, entrenar un modelo de Machine Learning e inferir predicciones con datos nuevos utilizando `XGBoost`.

## ğŸ“ **Estructura del Repositorio**

```
project
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py  # Funciones para procesamiento de datos
â”‚   â”œâ”€â”€ training.py       # Funciones para entrenar el modelo
â”‚   â”œâ”€â”€ inference.py      # Funciones para generar predicciones
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ raw.csv          # Datos crudos
â”‚   â”œâ”€â”€ prep.csv         # Datos preprocesados* (se debe de ejecutar cÃ³digo)
â”‚   â”œâ”€â”€ inference.csv    # Datos de inferencia
â”‚   â”œâ”€â”€ predictions.csv  # Predicciones generadas* (se debe de ejecutar cÃ³digo)
â”‚   â”œâ”€â”€ trained_columns.json # Columnas usadas en el entrenamiento* (se debe de ejecutar cÃ³digo)
â”œâ”€â”€ prep.py             # Script de preprocesamiento
â”œâ”€â”€ train.py            # Script de entrenamiento del modelo
â”œâ”€â”€ inference.py        # Script de inferencia
â””â”€â”€ model.joblib        # Modelo entrenado* (se debe de ejecutar cÃ³digo)
```

## ğŸ“œ **ExplicaciÃ³n de Scripts y MÃ³dulos**

### **Scripts en la raÃ­z del repositorio:**
- `prep.py`: Ejecuta el preprocesamiento de datos.
- `train.py`: Entrena el modelo XGBoost y guarda las columnas utilizadas en el entrenamiento.
- `inference.py`: Realiza inferencia con nuevos datos usando el modelo entrenado.

### **MÃ³dulos en `src/`:**
- `preprocessing.py`: Contiene funciones para la limpieza de datos, imputaciÃ³n de valores nulos, transformaciÃ³n y selecciÃ³n de caracterÃ­sticas.
- `training.py`: Incluye funciones para entrenar un modelo XGBoost, realizar optimizaciÃ³n de hiperparÃ¡metros y guardar el modelo.
- `inference.py`: Proporciona funciones para cargar un modelo, preparar datos de inferencia y generar predicciones.

---

## ğŸš€ **EjecuciÃ³n del Flujo Completo**

### **1ï¸âƒ£ Preprocesamiento de Datos**
```bash
python prep.py --input data/raw.csv --output data/prep.csv --target SalePrice
```
âœ… **Salida esperada:** `data/prep.csv` generado.

### **2ï¸âƒ£ Entrenamiento del Modelo**
```bash
python train.py --input data/prep.csv --output_model model.joblib --output_columns data/trained_columns.json --target SalePrice
```
âœ… **Salida esperada:** `model.joblib` y `data/trained_columns.json` generados.

### **3ï¸âƒ£ GeneraciÃ³n de Predicciones**
```bash
python inference.py --input data/inference.csv --model model.joblib --columns data/trained_columns.json --output data/predictions.csv
```
âœ… **Salida esperada:** `data/predictions.csv` generado.

---

## ğŸ›  **Herramientas Utilizadas**
- `pandas`, `numpy` â†’ ManipulaciÃ³n de datos
- `scikit-learn` â†’ Preprocesamiento y mÃ©tricas
- `xgboost` â†’ Algoritmo de aprendizaje
- `joblib` â†’ Guardado de modelos
- `loguru` â†’ Manejo de logs
- `argparse` â†’ ParÃ¡metros en CLI
- `black`, `flake8`, `pylint` â†’ Estilo y calidad de cÃ³digo

```
pandas==1.5.3
numpy==1.23.5
scikit-learn==1.2.2
xgboost==1.7.3
joblib==1.2.0
loguru==0.6.0
argparse==1.4.0
black==22.3.0
flake8==5.0.4
pylint==2.15.5
```

---

## ğŸ“Œ **Notas Importantes**
âœ… Asegurar que los archivos de datos (`raw.csv`, `inference.csv`) estÃ©n en la carpeta `data/` antes de ejecutar los scripts.
âœ… `trained_columns.json` debe existir para que la inferencia funcione correctamente.
âœ… El cÃ³digo estÃ¡ optimizado para ser modular y reutilizable en producciÃ³n.

---

## ğŸ“¬ **Contacto y Contribuciones**
Si tienes mejoras o encuentras errores, por favor crea un **issue** o un **pull request** en este repositorio.
